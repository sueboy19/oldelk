input {
	beats {
		port => 5044
		host => "0.0.0.0"
	}
}

## Add your filters / logstash plugins configuration here
# https://www.elastic.co/guide/en/logstash/current/logstash-config-for-filebeat-modules.html#parsing-nginx
# TODO
#
filter {
  if [etltype] == "blocks" { #[fields][srctype]
    csv {
      columns => [
        "number", "hash",  "parent_hash",  "nonce",  "sha3_uncles",  "logs_bloom",  "transactions_root",
        "state_root",  "receipts_root",  "miner",  "difficulty",  "total_difficulty",  "size",  "extra_data",
        "gas_limit",  "gas_used",  "timestamp",  "transaction_count"
      ]
      separator => ","
      remove_field => ["message"]
      skip_empty_columns => true
      #skip_empty_rows => true
    }
  }else if [etltype] == "transactions" { #[fields][srctype]
    csv {
      columns => [
        "hash",  "nonce",  "block_hash",  "block_number",  "transaction_index",  "from_address",  
        "to_address",  "value",  "gas",  "gas_price",  "inputcontext"
      ]
      separator => ","
      remove_field => ["message"]
      skip_empty_columns => true
      #skip_empty_rows => true
    }
  }else if [etltype] == "token_transfers" { #[fields][srctype]
    csv {
      columns => [
        "token_address",  "from_address",  "to_address",  "value",  "transaction_hash",  "log_index", 
        "block_number" 
      ]
      separator => ","
      remove_field => ["message"]
      skip_empty_columns => true
      #skip_empty_rows => true
    }
  }else if [etltype] == "receipts" { #[fields][srctype]
    csv {
      columns => [
        "transaction_hash",  "transaction_index",  "block_hash",  "block_number",  "cumulative_gas_used",  
        "gas_used",  "contract_address",  "root",  "status"
      ]
      separator => ","
      remove_field => ["message"]
      skip_empty_columns => true
      #skip_empty_rows => true
    }
  }else if [etltype] == "logs" { #[fields][srctype]
    csv {
      columns => [
        "log_index",  "transaction_hash",  "transaction_index",  "block_hash",  "block_number",  
        "address",  "data", "topics"
      ]
      separator => ","
      remove_field => ["message"]
      skip_empty_columns => true
      #skip_empty_rows => true
    }
  }else if [etltype] == "contracts" { #[fields][srctype]
    csv {
      columns => [
        "address",  "bytecode",  "function_sighashes",  "is_erc20",  "is_erc721"
      ]
      separator => ","
      remove_field => ["message"]
      skip_empty_columns => true
      #skip_empty_rows => true
    }
  }else if [etltype] == "tokens" { #[fields][srctype]
    csv {
      columns => [
        "address",  "symbol",  "name",  "decimals",  "total_supply"
      ]
      separator => ","
      remove_field => ["message"]
      skip_empty_columns => true
      #skip_empty_rows => true
    }
  }else if [etltype] == "traces" { #[fields][srctype]
    csv {
      columns => [
        "block_number",  "transaction_hash",  "transaction_index",  "from_address",  "to_address",
        "value",  "inputcontext",  "output",  "trace_type",  "call_type",  "reward_type",  "gas",
        "gas_used",  "subtraces",  "trace_address",  "error"
      ]
      separator => ","
      remove_field => ["message"]
      skip_empty_columns => true
      #skip_empty_rows => true
    }
  }else if [fileset][module] == "nginx" {
    if [fileset][name] == "access" {
      grok {
        match => { "message" => ["%{IPORHOST:[nginx][access][remote_ip]} - %{DATA:[nginx][access][user_name]} \[%{HTTPDATE:[nginx][access][time]}\] \"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][url]} HTTP/%{NUMBER:[nginx][access][http_version]}\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \"%{DATA:[nginx][access][referrer]}\" \"%{DATA:[nginx][access][agent]}\""] }
        remove_field => "message"
      }
      mutate {
        add_field => { "read_timestamp" => "%{@timestamp}" }
      }
      date {
        match => [ "[nginx][access][time]", "dd/MMM/YYYY:H:m:s Z" ]
        remove_field => "[nginx][access][time]"
      }
      useragent {
        source => "[nginx][access][agent]"
        target => "[nginx][access][user_agent]"
        remove_field => "[nginx][access][agent]"
      }
      geoip {
        source => "[nginx][access][remote_ip]"
        target => "[nginx][access][geoip]"
      }
    }
    else if [fileset][name] == "error" {
      grok {
        match => { "message" => ["%{DATA:[nginx][error][time]} \[%{DATA:[nginx][error][level]}\] %{NUMBER:[nginx][error][pid]}#%{NUMBER:[nginx][error][tid]}: (\*%{NUMBER:[nginx][error][connection_id]} )?%{GREEDYDATA:[nginx][error][message]}"] }
        remove_field => "message"
      }
      mutate {
        rename => { "@timestamp" => "read_timestamp" }
      }
      date {
        match => [ "[nginx][error][time]", "YYYY/MM/dd H:m:s" ]
        remove_field => "[nginx][error][time]"
      }
    }
  }else if [srctype] == "geth" { #[fields][srctype]
    grok {
      match => ["message", "%{LOGLEVEL:logType} \[%{DATA:gethmm}-%{DATA:gethdd}\|%{DATA:gethtime}\] %{GREEDYDATA:tmessage}\s+epoch=(?<epoch>\b\w+\b) percentage=(?<percentage>\b\w+\b)\s+elapsed=(?<elapsed>\b\w+\b)"]
      add_field => ["gethdate", "%{[gethmm]}-%{[gethdd]} %{[gethtime]}"]
      add_field => [ "filterDAG", "true" ]
      add_field => [ "geth_ip", "%{[filebeatserverip]}" ]
    }
    grok {
      match => ["message", "%{LOGLEVEL:logType} \[%{DATA:gethmm}-%{DATA:gethdd}\|%{DATA:gethtime}\] %{DATA:tmessage} number=(?<minedNumber>\b\w+\b) hash=(?<minedHashr>\b\w+...\w+\b) td=(?<minedtd>\b\w+\b) age=(?<minedtd>\b\w+\b)%{DATA:message2}"]
      add_field => ["gethdate", "%{[gethmm]}-%{[gethdd]} %{[gethtime]}"]
      add_field => [ "filterMineLoad", "true" ]
      add_field => [ "geth_ip", "%{[filebeatserverip]}" ]
    }
    grok {
      match => ["message", "%{LOGLEVEL:logType} \[%{DATA:gethmm}-%{DATA:gethdd}\|%{DATA:gethtime}\] %{GREEDYDATA:tmessage} number=(?<minedNumber>\b\w+\b) hash=(?<minedHashr>\b\w+...\w+\b)"]
      add_field => ["gethdate", "%{[gethmm]}-%{[gethdd]} %{[gethtime]}"]
      add_field => [ "filterMined", "true" ]
      add_field => [ "geth_ip", "%{[filebeatserverip]}" ]
      #  "minedNumber" => "%{minedNumber}" 
      #  "minedHashr" => "%{minedHashr}" 
    }
    ruby {
      #補上geth log沒有年份問題，可能會產生跨年時，少數log的gethdate有誤差到明年年底
      code => 
        " tstamp = event.get('@timestamp').to_i
          event.set('epoch',tstamp)
          event.set('gethdate', Time.at(tstamp).strftime('%Y')+'-'+event.get('gethdate'))
        "
    }
  }else if [srctype] == "secure" {
    grok {
      #type => "syslog"
      match => ["message", "%{SYSLOGBASE} Failed password for %{USERNAME:username} from %{IP:src_ip} port %{BASE10NUM:port} ssh2"]
      add_tag => "ssh_brute_force_attack"
    }
    grok {
      #type => "syslog"
      match => ["message", "%{SYSLOGBASE} Accepted password for %{USERNAME:username} from %{IP:src_ip} port %{BASE10NUM:port} ssh2"]
      add_tag => "ssh_sucessful_login"
    }
  }else{
    json {
      source => "message"
    }
  }

  #無效
  #grok {
  #  match => ["[@metadata][timestamp]", "%{DATA:mm} %{DATA:dd} %{DATA:year}, %{GREEDYDATA:time}"]
  #  add_field => ["year", "%{[year]}"]
  #}

  grok {
    match => [ "source", "/var/log/hardblue/%{DATA:application}.log" ]
  }

  grok{
    #break_on_match => false
    #match => { "message" => "%{COMBINEDAPACHELOG}+%{GREEDYDATA:extra_fields}" }
    match => [ "message", "%{DATA:message}" ]
    add_field => [ "filterNormal", "true" ]
  }
  geoip {
    source => "geth_ip"
    target => "gethipgeoip"
    add_tag => [ "geth-geoip" ]
    add_field => [ "geoipflag", "true" ]
  }
  geoip {
    source => "secure_ip"
    target => "secureipgeoip"
    add_tag => [ "secure-geoip" ]
    add_field => [ "geoipflag", "true" ]
  }
  #  geoip {  
  #    source => "monitor_ip"
  #    target => "geoip"
  #    add_tag => [ "monitor-geoip" ]
  #    add_field => [ "geoipflag", "true" ]
  #  }
  #  mutate { add_tag => "monitorflg" }
  
  geoip {
    source => "clientip"
    target => "geoip"
    add_tag => [ "nginx-geoip" ]
    add_field => [ "geoipflag", "true" ]
  }
  geoip {
    source => "src_ip"
    target => "srcipgeoip"
    add_tag => [ "ssh-geoip" ]
    add_field => [ "geoipflag", "true" ]
  }
  geoip {
    source => "filebeatserverip"
    target => "filebeatserveripgeoip"
    add_tag => [ "filebeat-geoip" ]
    add_field => [ "geoipflag", "true" ]
  }
  mutate {
    convert => ["response", "integer"]
    convert => ["bytes", "integer"]
    convert => ["responsetime", "float"]
    remove_field => [ "tmessage" ]
  }
  date {
    match => [ "gethdate" , "YYYY-MM-dd HH:mm:ss"]
    target => "gethdate"
    timezone => "Asia/Taipei"
  }
  date {
    match => [ "timestamp" , "dd/MMM/YYYY:HH:mm:ss Z" ]
    remove_field => [ "timestamp" ]
  }
  useragent {
    source => "agent"
  }
}

output {
  if [etltype] == "blocks" {
    elasticsearch {
      hosts => "elasticsearch:9200"
      manage_template => false
      index => "%{[@metadata][beat]}-%{[@metadata][version]}-etl-blocks"
      document_id => "%{[hash]}"
    }
  }else if [etltype] == "transactions" {
    elasticsearch {
      hosts => "elasticsearch:9200"
      manage_template => false
      index => "%{[@metadata][beat]}-%{[@metadata][version]}-etl-transactions"
      document_id => "%{[hash]}"
    }
  }else if [etltype] == "token_transfers" {
    elasticsearch {
      hosts => "elasticsearch:9200"
      manage_template => false
      index => "%{[@metadata][beat]}-%{[@metadata][version]}-etl-token_transfers"
    }
  }else if [etltype] == "receipts" {
    elasticsearch {
      hosts => "elasticsearch:9200"
      manage_template => false
      index => "%{[@metadata][beat]}-%{[@metadata][version]}-etl-receipts"
    }
  }else if [etltype] == "logs" {
    elasticsearch {
      hosts => "elasticsearch:9200"
      manage_template => false
      index => "%{[@metadata][beat]}-%{[@metadata][version]}-etl-logs"
    }
  }else if [etltype] == "contracts" {
    elasticsearch {
      hosts => "elasticsearch:9200"
      manage_template => false
      index => "%{[@metadata][beat]}-%{[@metadata][version]}-etl-contracts"
      document_id => "%{[address]}"
    }
  }else if [etltype] == "tokens" {
    elasticsearch {
      hosts => "elasticsearch:9200"
      manage_template => false
      index => "%{[@metadata][beat]}-%{[@metadata][version]}-etl-tokens"
      document_id => "%{[hash]}"
    }
  }else if [etltype] == "traces" {
    elasticsearch {
      hosts => "elasticsearch:9200"
      manage_template => false
      index => "%{[@metadata][beat]}-%{[@metadata][version]}-etl-traces"
      document_id => "%{[hash]}"
    }
  }else if [fileset][module] == "nginx" {
    if [fileset][name] == "access" {
      elasticsearch {
        hosts => "elasticsearch:9200"
        manage_template => false
        index => "%{[@metadata][beat]}-%{[@metadata][version]}-etl-nginx-access-%{+YYYY.MM.dd}"
      }
    }else if [fileset][name] == "error" {
      elasticsearch {
        hosts => "elasticsearch:9200"
        manage_template => false
        index => "%{[@metadata][beat]}-%{[@metadata][version]}-etl-nginx-error-%{+YYYY.MM.dd}"
      }
    }
  }else if [srctype] == "geth" {
    elasticsearch {
      hosts => "elasticsearch:9200"
      manage_template => false
      index => "%{[@metadata][beat]}-%{[@metadata][version]}-etl-geth-%{+YYYY.MM.dd}"
    }
  }else{

    elasticsearch {
      hosts => "elasticsearch:9200"
      manage_template => false
      index => "%{[@metadata][beat]}-%{[@metadata][version]}-etl-%{+YYYY.MM.dd}"
    }
  }

	stdout { codec => rubydebug  }
}
